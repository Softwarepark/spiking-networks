{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, SnapshotObjectType, OperationStatusType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://softwarepark-face-api.cognitiveservices.azure.com/\"\n",
    "KEY = \"30d0899c3a6c4a10b2e6bdc3e2d19ddc\"\n",
    "\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))\n",
    "def get_path(p):\n",
    "    return os.path.join(\"/home/jupyter/images/\", p)\n",
    "\n",
    "def mark_faces(file, detected_faces):\n",
    "    img = Image.open(get_path(file))\n",
    "\n",
    "    # For each face returned use the face rectangle and draw a red box.\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_faces:\n",
    "        draw.rectangle(getRectangle(face), outline='pink', width=3)\n",
    "\n",
    "    img.thumbnail((600,600), Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "def detect_faces(file):\n",
    "    \n",
    "    # Detect a face in an image that contains a single face\n",
    "    \n",
    "\n",
    "    with open(get_path(file), 'r+b') as f:\n",
    "        profile_faces = face_client.face.detect_with_stream(f)\n",
    "    if not profile_faces:\n",
    "        raise Exception('No profile detected from image {}'.format(file))\n",
    "    return profile_faces\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_name = 'rinat_avatar.jpg'\n",
    "scene_name = \"rinat_identify.jpg\"\n",
    "\n",
    "profile_faces = detect_faces(profile_path)\n",
    "detected_faces = detect_faces(scene_name)\n",
    "\n",
    "result = face_client.face.verify_face_to_face(profile_face.face_id, detected_faces[0].face_id)\n",
    "print(f'{\"Same\" if result.is_identical else \"Different \"} person, {result.confidence}')\n",
    "\n",
    "mark_faces(scene_name, detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import numpy as np\n",
    "from fawkes.differentiator import FawkesMaskGeneration\n",
    "from fawkes.utils import load_extractor, init_gpu, select_target_label, dump_image, reverse_process_cloaked, \\\n",
    "    Faces, filter_image_paths\n",
    "\n",
    "from fawkes.align_face import aligner\n",
    "from fawkes.utils import get_file\n",
    "from fawkes.protection import Fawkes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "batch_size = 1\n",
    "feature_extractor = \"high_extract\"\n",
    "protector = Fawkes(feature_extractor, 0, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--directory', '-d', type=str,\n",
    "                    help='the directory that contains images to run protection', default='imgs/')\n",
    "\n",
    "parser.add_argument('--gpu', '-g', type=str,\n",
    "                    help='the GPU id when using GPU for optimization', default='0')\n",
    "\n",
    "parser.add_argument('--mode', '-m', type=str,\n",
    "                    help='cloak generation mode, select from min, low, mid, high. The higher the mode is, the more perturbation added and stronger protection',\n",
    "                    default='min')\n",
    "\n",
    "parser.add_argument('--feature-extractor', type=str,\n",
    "                    help=\"name of the feature extractor used for optimization, currently only support high_extract\",\n",
    "                    default=\"high_extract\")\n",
    "\n",
    "parser.add_argument('--th', help='only relevant with mode=custom, DSSIM threshold for perturbation', type=float,\n",
    "                    default=0.01)\n",
    "parser.add_argument('--max-step', help='only relevant with mode=custom, number of steps for optimization', type=int,\n",
    "                    default=1000)\n",
    "parser.add_argument('--sd', type=int, help='only relevant with mode=custom, penalty number, read more in the paper',\n",
    "                    default=1e9)\n",
    "parser.add_argument('--lr', type=float, help='only relevant with mode=custom, learning rate', default=2)\n",
    "\n",
    "parser.add_argument('--batch-size', help=\"number of images to run optimization together\", type=int, default=1)\n",
    "parser.add_argument('--separate_target', help=\"whether select separate targets for each faces in the directory\",\n",
    "                    action='store_true')\n",
    "parser.add_argument('--no-align', help=\"whether to detect and crop faces\",\n",
    "                    action='store_true')\n",
    "parser.add_argument('--debug', help=\"turn on debug and copy/paste the stdout when reporting an issue on github\",\n",
    "                    action='store_true')\n",
    "parser.add_argument('--format', type=str,\n",
    "                    help=\"format of the output image\",\n",
    "                    default=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.mode=\"ultra\"\n",
    "protector.run_protection([get_path(profile_name)], mode=args.mode, th=args.th, sd=args.sd, lr=args.lr,\n",
    "                                 max_step=args.max_step,\n",
    "                                 batch_size=args.batch_size, format=args.format,\n",
    "                                 separate_target=args.separate_target, debug=args.debug, no_align=args.no_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_face = detect_faces(\"rinat_avatar.jpg\")[0]\n",
    "cloaked_face = detect_faces(\"rinat_profile_high_cloaked.png\")[0]\n",
    "\n",
    "result = face_client.face.verify_face_to_face(original_face.face_id, detected_faces[0].face_id)\n",
    "print(f'Original: {\"Same\" if result.is_identical else \"Different \"} person, {result.confidence}')\n",
    "\n",
    "result = face_client.face.verify_face_to_face(cloaked_face.face_id, detected_faces[0].face_id)\n",
    "print(f'Cloaked: {\"Same\" if result.is_identical else \"Different \"} person, {result.confidence}')\n",
    "\n",
    "mark_faces(scene_path, detected_faces)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
